{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Estimation for Machine/Human Translation (Supervised Approach)\n",
    "\n",
    "**Author:** Jessica Silva\n",
    "\n",
    "**Keywords:** Quality Estimation; Machine Translation; Word-level; Sentence-level\n",
    "\n",
    "**Date:** 20/07/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this research is to understand and evaluate the quality estimation task for machine/human translation. The goal of this task is to assess the quality of a translation without access to reference translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Which strategies can be used for measuring quality of translations? In which cases can they be applied? \n",
    "\n",
    "2) Which kind of data and how much data is necessary to train this approaches? \n",
    "\n",
    "3) Gains with the new approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Outcomes <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Which strategies can be used for measuring quality of machine translations? In which cases can they be applied? \n",
    "\n",
    "-\n",
    "\n",
    "2) Which kind of data and how much data is necessary to train this approaches?\n",
    "\n",
    "-\n",
    "\n",
    "3) Gains with the new approach.\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "\t<ul class=\"toc-item\">\n",
    "\t\t<li>\n",
    "\t\t\t<span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-1\">\n",
    "\t\t\t\t<span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Problem Statement</a>\n",
    "\t\t\t</span>\n",
    "\t\t</li>\n",
    "\t\t<li>\n",
    "\t\t\t<span><a href=\"#Experimental-Setup\" data-toc-modified-id=\"Experimental-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Experimental Setup</a></span>\n",
    "\t\t</li>\n",
    "\t\t<li>\n",
    "\t\t\t<span><a href=\"#Predictor-Estimator\" data-toc-modified-id=\"Predictor-Estimator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Predictor-Estimator</a></span>\n",
    "\t\t\t<ul class=\"toc-item\">\n",
    "\t\t\t\t<li>\n",
    "\t\t\t\t\t<span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Dataset</a></span>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<span><a href=\"#TrainPredict\" data-toc-modified-id=\"TrainPredict-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train and Predict</a></span>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "                    <span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Evaluation</a></span>\n",
    "                </li>\n",
    "\t\t\t</ul>\n",
    "\t\t</li>\n",
    "\t\t<li>\n",
    "\t\t\t<span><a href=\"#Benchmarks\" data-toc-modified-id=\"Benchmarks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Benchmarks</a></span>\n",
    "\t\t</li>\n",
    "\t\t<li>\n",
    "\t\t\t<span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Future Work</a></span>\n",
    "\t\t</li>\n",
    "\t</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Problem Statement\n",
    "\n",
    "Assess the quality of a translation system/human without access to reference translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Experimental Setup \n",
    "\n",
    "Before being able to run Quality Estimation Tutorial, there is a small setup required. Please check the README.md before continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Predictor-Estimator\n",
    "\n",
    "The Predictor-Estimator architecture can measure the quality in the word and sentence level:\n",
    "\n",
    "* **Word-level**:\n",
    "The goal of the word-level QE task using the Predictor-Estimator is to assign quality labels (OK or BAD) to each translated word, as well as to gaps between words (to account for context that needs to be inserted), and source words (to denote words in the original sentence that have been mistranslated or omitted in the target).\n",
    "\n",
    "* **Sentence-level**:\n",
    "The goal of the Sentence-level QE task using the Predictor-Estimator is to predict the quality of the whole translated sentence, based on how many edit operations are required to fix it, in terms of HTER (Human Translation Error Rate).\n",
    "\n",
    "### Architecture\n",
    "\n",
    "* Predictor: trained to predict each token of the target sentence given the source and the left and right context of the target sentence (one biLSTM)\n",
    "\n",
    "* Estimator: takes features produced by the predictor and uses them to classify each word as OK or BAD (two LSTMs)\n",
    "\n",
    "* Multi-task architecture for sentence-level HTER scores\n",
    "\n",
    "<img src='images/predictor-estimator.png' width='400'>\n",
    "\n",
    "[Paper](https://www.aclweb.org/anthology/W17-4763.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Quality Estimation task, we need two types of corpus, one to train the Predictor model and another to train the Estimator model.\n",
    "\n",
    "### Predictor data\n",
    "\n",
    "The Predictor is trained to predict each token of the target sentence given the source and the left and right context of the target sentence (one biLSTM)\n",
    "\n",
    "* **Format**: ( _src, tgt_ )\n",
    "\n",
    "_src: Sentences in the source language_\n",
    "\n",
    "_tgt: Sentences in the target language_\n",
    "\n",
    "* **tags**: _no tags (raw data)_\n",
    "\n",
    "<img src='images/dataset-table1.png' width='500'>\n",
    "\n",
    "### Estimator data\n",
    "\n",
    "The Estimator takes features produced by the predictor and uses them to classify each word as OK or BAD (two LSTMs) and to predict HTER.\n",
    "\n",
    "* **Format**: ( _src, mt, pe_ )\n",
    "\n",
    "_src: Sentences in the source language_\n",
    "\n",
    "_mt: Machine translated sentences (target language)_\n",
    "\n",
    "_pe: post-edited sentences (target language)_\n",
    "\n",
    "* **tags**: _binary tags (OK and BAD), HTER score_\n",
    "\n",
    "<img src='images/dataset-table2.png' width='800'>\n",
    "\n",
    "**Ways to create the post-edited data**\n",
    "* By human translators\n",
    "* By Automatic post-editing systems\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/pedrobalage/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src import utils\n",
    "import yaml\n",
    "import kiwi\n",
    "from ipywidgets import interact, fixed, Textarea\n",
    "from functools import partial\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-25 16:15:41--  https://github.com/Unbabel/KiwiCutter/releases/download/v1.0/estimator_en_de.torch.zip\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/207818502/4a7c2b80-dab8-11e9-8d9f-716248c800da?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200825%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200825T151410Z&X-Amz-Expires=300&X-Amz-Signature=dcc1e0a1ddb2f46cef3c48a15a792d1924e22a216468e3a5e9eea9d4a1ace5e6&X-Amz-SignedHeaders=host&actor_id=0&repo_id=207818502&response-content-disposition=attachment%3B%20filename%3Destimator_en_de.torch.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2020-08-25 16:15:41--  https://github-production-release-asset-2e65be.s3.amazonaws.com/207818502/4a7c2b80-dab8-11e9-8d9f-716248c800da?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200825%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200825T151410Z&X-Amz-Expires=300&X-Amz-Signature=dcc1e0a1ddb2f46cef3c48a15a792d1924e22a216468e3a5e9eea9d4a1ace5e6&X-Amz-SignedHeaders=host&actor_id=0&repo_id=207818502&response-content-disposition=attachment%3B%20filename%3Destimator_en_de.torch.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.105.219\n",
      "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.105.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 360477809 (344M) [application/octet-stream]\n",
      "Saving to: ‘../data/interim/estimator_en_de.torch.zip’\n",
      "\n",
      "estimator_en_de.tor 100%[===================>] 343,78M  27,9MB/s    in 13s     \n",
      "\n",
      "2020-08-25 16:15:55 (25,8 MB/s) - ‘../data/interim/estimator_en_de.torch.zip’ saved [360477809/360477809]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Unbabel/KiwiCutter/releases/download/v1.0/estimator_en_de.torch.zip -P ../data/interim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../data/interim/estimator_en_de.torch.zip\n",
      "  inflating: ../data/interim/estimator_en_de.torch  \n"
     ]
    }
   ],
   "source": [
    "!unzip ../data/interim/estimator_en_de.torch.zip -d ../data/interim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kiwi.load_model('../data/interim/estimator_en_de.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ['to convert a smooth point to a corner point without direction lines , click the smooth point .']\n",
    "target = ['soll ein Übergangspunkt in einen Eckpunkt ohne Grifflinien umgewandelt werden , klicken Sie auf den Glättungspunkt .']\n",
    "examples = {'source': source,'target': target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [[0.06895697116851807,\n",
       "   0.4229596257209778,\n",
       "   0.21621333062648773,\n",
       "   0.05693240091204643,\n",
       "   0.14355583488941193,\n",
       "   0.08891278505325317,\n",
       "   0.2814420461654663,\n",
       "   0.7454012036323547,\n",
       "   0.45772698521614075,\n",
       "   0.21983414888381958,\n",
       "   0.0320119746029377,\n",
       "   0.04847194254398346,\n",
       "   0.024298403412103653,\n",
       "   0.2455146610736847,\n",
       "   0.25810056924819946,\n",
       "   0.6393271684646606,\n",
       "   0.011077080853283405]],\n",
       " 'gap_tags': [[0.005333846900612116,\n",
       "   0.5178709030151367,\n",
       "   0.010363646782934666,\n",
       "   0.2994779050350189,\n",
       "   0.009245308116078377,\n",
       "   0.0038670392241328955,\n",
       "   0.33894485235214233,\n",
       "   0.3496887683868408,\n",
       "   0.056504152715206146,\n",
       "   0.0010272195795550942,\n",
       "   0.012129525654017925,\n",
       "   0.02781379036605358,\n",
       "   0.00022671371698379517,\n",
       "   0.16732671856880188,\n",
       "   0.019436508417129517,\n",
       "   0.18383103609085083,\n",
       "   0.09625448286533356,\n",
       "   0.008517248556017876]],\n",
       " 'sentence_scores': [0.1539330631494522]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTER: 0.14097408950328827\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " <span style='color:green'>soll</span> <span style='color:green'>ein</span> <span style='color:red'>*Übergangspunkt*</span> <span style='color:green'>in</span> <span style='color:green'>einen</span> <span style='color:green'>Eckpunkt</span> <span style='color:green'>ohne</span> <span style='color:red'>*Grifflinien*</span> <span style='color:green'>umgewandelt</span> <span style='color:green'>werden</span> <span style='color:green'>,</span> <span style='color:green'>klicken</span> <span style='color:green'>Sie</span> <span style='color:green'>auf</span> <span style='color:green'>den</span> <span style='color:red'>*Glättungspunkt*</span> <span style='color:green'>.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SOURCE = Textarea(value=source[0], layout={'width': '90%'})\n",
    "MT = Textarea(value=target[0], layout={'width': '90%'})\n",
    "_interact = interact(utils.KiwiViz, model=fixed(model), source=SOURCE, mt=MT, threshold=(0.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings\n",
    "\n",
    "I suggest the following complementary readings on Quality Estimation\n",
    "\n",
    "* A really good [book](https://www.morganclaypool.com/doi/abs/10.2200/S00854ED1V01Y201805HLT039) of Quality Estimation from Lucia Specia et al.\n",
    "* [Predictor-Estimator architecture paper](https://www.aclweb.org/anthology/W17-4763.pdf)\n",
    "* The [main conference on Machine Translation](http://www.statmt.org/wmt20/) and the [Quality Estimation](http://www.statmt.org/wmt20/quality-estimation-task.html) shared task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [Quality Estimation for Machine Translation](https://www.morganclaypool.com/doi/abs/10.2200/S00854ED1V01Y201805HLT039) \n",
    "\n",
    "[2] [Unsupervised Quality Estimation for Neural Machine Translation](https://arxiv.org/abs/2005.10608)\n",
    "\n",
    "[3] [Unbabel's Participation in the WMT19 Translation Quality Estimation Shared Task](https://arxiv.org/abs/1907.10352)\n",
    "\n",
    "[4] [OpenKiwi: An Open Source Framework for Quality Estimation](https://arxiv.org/abs/1902.08646)\n",
    "\n",
    "[5] [Quality In, Quality Out: Learning from Actual Mistakes](https://fredblain.org/transfer-learning-qe.html)\n",
    "\n",
    "[6] [Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation](https://arxiv.org/pdf/2004.09813.pdf)\n",
    "\n",
    "[7] [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)\n",
    "\n",
    "[8] [Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond](https://arxiv.org/pdf/1812.10464.pdf)\n",
    "\n",
    "[9] [BERTSCORE: EVALUATING TEXT GENERATION WITH BERT](https://arxiv.org/pdf/1904.09675.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
